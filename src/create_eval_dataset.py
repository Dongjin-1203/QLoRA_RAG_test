"""
í‰ê°€ ë°ì´í„°ì…‹ ìƒì„± ë„êµ¬

ì‹¤ì œ RFP ë¬¸ì„œì—ì„œ ì§ˆë¬¸-ë‹µë³€ ìŒì„ ë§Œë“¤ì–´
Ground Truthê°€ ìˆëŠ” í‰ê°€ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python create_eval_dataset.py --input data/rag_chunks_final.csv --output data/eval_dataset.json
"""

import json
import csv
import argparse
from pathlib import Path
from typing import List, Dict, Any


class EvalDatasetCreator:
    """í‰ê°€ ë°ì´í„°ì…‹ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.dataset = {
            "metadata": {
                "version": "1.0",
                "description": "RFPilot í‰ê°€ ë°ì´í„°ì…‹",
                "created_by": "manual_annotation"
            },
            "in_distribution": [],
            "out_distribution": []
        }
    
    def add_in_distribution_sample(
        self,
        query: str,
        expected_answer: str,
        category: str,
        source_doc: str = None,
        metadata: Dict[str, Any] = None
    ):
        """In-Distribution ìƒ˜í”Œ ì¶”ê°€"""
        sample = {
            "query": query,
            "expected_answer": expected_answer,
            "category": category,
            "expected_type": "document",
            "source_doc": source_doc,
            "metadata": metadata or {}
        }
        self.dataset["in_distribution"].append(sample)
    
    def add_out_distribution_sample(
        self,
        query: str,
        expected_answer: str,
        category: str,
        metadata: Dict[str, Any] = None
    ):
        """Out-Distribution ìƒ˜í”Œ ì¶”ê°€"""
        sample = {
            "query": query,
            "expected_answer": expected_answer,
            "category": category,
            "expected_type": "out_of_scope",
            "metadata": metadata or {}
        }
        self.dataset["out_distribution"].append(sample)
    
    def create_template_dataset(self):
        """í…œí”Œë¦¿ ë°ì´í„°ì…‹ ìƒì„± (ìˆ˜ë™ ì‘ì„±ìš©)"""
        print("ğŸ“ í…œí”Œë¦¿ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        # In-Distribution í…œí”Œë¦¿
        in_dist_templates = [
            {
                "query": "ì‚¬ì—… ì œì•ˆì„œ ì œì¶œ ë§ˆê°ì¼ì€ ì–¸ì œì¸ê°€ìš”?",
                "expected_answer": "2024ë…„ 3ì›” 15ì¼ê¹Œì§€ì…ë‹ˆë‹¤.",  # ì‹¤ì œ ë¬¸ì„œì—ì„œ ì¶”ì¶œ
                "category": "deadline",
                "source_doc": "RFP_2024_001.hwp",
                "metadata": {"difficulty": "easy"}
            },
            {
                "query": "ì œì•ˆ ìš”ì²­ì„œì˜ ì œì¶œ ì„œë¥˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "expected_answer": "ê¸°ìˆ ì œì•ˆì„œ, ê°€ê²©ì œì•ˆì„œ, ì‚¬ì—…ìë“±ë¡ì¦, íšŒì‚¬ì†Œê°œì„œê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                "category": "requirements",
                "source_doc": "RFP_2024_001.hwp",
                "metadata": {"difficulty": "medium"}
            },
            {
                "query": "ì‚¬ì—… ì˜ˆì‚° ê·œëª¨ëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
                "expected_answer": "ì´ 5ì–µì›ì…ë‹ˆë‹¤.",
                "category": "budget",
                "source_doc": "RFP_2024_002.hwp",
                "metadata": {"difficulty": "easy"}
            },
        ]
        
        # Out-Distribution í…œí”Œë¦¿
        out_dist_templates = [
            {
                "query": "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?",
                "expected_answer": "ì„œìš¸ì…ë‹ˆë‹¤.",
                "category": "general_knowledge",
                "metadata": {"difficulty": "easy"}
            },
            {
                "query": "íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "expected_answer": "ë¦¬ìŠ¤íŠ¸ëŠ” ê°€ë³€(mutable)ì´ê³ , íŠœí”Œì€ ë¶ˆë³€(immutable)ì…ë‹ˆë‹¤.",
                "category": "programming",
                "metadata": {"difficulty": "medium"}
            },
        ]
        
        # ë°ì´í„°ì…‹ì— ì¶”ê°€
        for sample in in_dist_templates:
            self.add_in_distribution_sample(**sample)
        
        for sample in out_dist_templates:
            self.add_out_distribution_sample(**sample)
        
        print(f"âœ… í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ")
        print(f"   - In-Distribution: {len(in_dist_templates)}ê°œ")
        print(f"   - Out-Distribution: {len(out_dist_templates)}ê°œ")
        print(f"\nâš ï¸ ì´ í…œí”Œë¦¿ì„ ìˆ˜ì •í•˜ì—¬ ì‹¤ì œ ë°ì´í„°ë¥¼ ì±„ì›Œì£¼ì„¸ìš”!")
    
    def load_from_csv(self, csv_path: str):
        """CSVì—ì„œ ë°ì´í„°ì…‹ ë¡œë“œ"""
        print(f"ğŸ“¥ CSV ë¡œë“œ ì¤‘: {csv_path}")
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                distribution = row.get('distribution', 'in_distribution')
                
                if distribution == 'in_distribution':
                    self.add_in_distribution_sample(
                        query=row['query'],
                        expected_answer=row['expected_answer'],
                        category=row['category'],
                        source_doc=row.get('source_doc'),
                        metadata=json.loads(row.get('metadata', '{}'))
                    )
                else:
                    self.add_out_distribution_sample(
                        query=row['query'],
                        expected_answer=row['expected_answer'],
                        category=row['category'],
                        metadata=json.loads(row.get('metadata', '{}'))
                    )
        
        print(f"âœ… CSV ë¡œë“œ ì™„ë£Œ")
    
    def save_json(self, output_path: str):
        """JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.dataset, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}")
    
    def save_csv_template(self, output_path: str):
        """ìˆ˜ë™ ì‘ì„±ìš© CSV í…œí”Œë¦¿ ì €ì¥"""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=[
                'distribution', 'query', 'expected_answer', 
                'category', 'source_doc', 'metadata'
            ])
            writer.writeheader()
            
            # In-Distribution ì˜ˆì‹œ
            writer.writerow({
                'distribution': 'in_distribution',
                'query': 'ì‚¬ì—… ì œì•ˆì„œ ì œì¶œ ë§ˆê°ì¼ì€ ì–¸ì œì¸ê°€ìš”?',
                'expected_answer': '2024ë…„ 3ì›” 15ì¼ê¹Œì§€ì…ë‹ˆë‹¤.',
                'category': 'deadline',
                'source_doc': 'RFP_2024_001.hwp',
                'metadata': '{"difficulty": "easy"}'
            })
            
            # Out-Distribution ì˜ˆì‹œ
            writer.writerow({
                'distribution': 'out_distribution',
                'query': 'í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?',
                'expected_answer': 'ì„œìš¸ì…ë‹ˆë‹¤.',
                'category': 'general_knowledge',
                'source_doc': '',
                'metadata': '{"difficulty": "easy"}'
            })
        
        print(f"ğŸ“„ CSV í…œí”Œë¦¿ ì €ì¥: {output_path}")
        print(f"   â†’ ì´ íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ ì‹¤ì œ ë°ì´í„°ë¥¼ ì±„ì›Œì£¼ì„¸ìš”!")
    
    def print_summary(self):
        """ë°ì´í„°ì…‹ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ë°ì´í„°ì…‹ ìš”ì•½")
        print("="*60)
        print(f"In-Distribution: {len(self.dataset['in_distribution'])}ê°œ")
        print(f"Out-Distribution: {len(self.dataset['out_distribution'])}ê°œ")
        print(f"ì´ ìƒ˜í”Œ: {len(self.dataset['in_distribution']) + len(self.dataset['out_distribution'])}ê°œ")
        print("="*60 + "\n")


def main():
    parser = argparse.ArgumentParser(description='í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±')
    parser.add_argument('--mode', choices=['template', 'csv'], default='template',
                        help='ìƒì„± ëª¨ë“œ: template (í…œí”Œë¦¿ ìƒì„±) ë˜ëŠ” csv (CSVì—ì„œ ë¡œë“œ)')
    parser.add_argument('--input', type=str, help='ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', type=str, default='data/eval_dataset.json',
                        help='ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--csv-template', type=str, default='data/eval_template.csv',
                        help='CSV í…œí”Œë¦¿ ì €ì¥ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    creator = EvalDatasetCreator()
    
    if args.mode == 'template':
        print("ğŸ“ í…œí”Œë¦¿ ëª¨ë“œ")
        creator.create_template_dataset()
        creator.save_json(args.output)
        creator.save_csv_template(args.csv_template)
    
    elif args.mode == 'csv':
        if not args.input:
            print("âŒ CSV ëª¨ë“œì—ì„œëŠ” --input ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        print("ğŸ“¥ CSV ëª¨ë“œ")
        creator.load_from_csv(args.input)
        creator.save_json(args.output)
    
    creator.print_summary()
    
    print("\nâœ… ì™„ë£Œ!")
    print(f"\në‹¤ìŒ ë‹¨ê³„:")
    print(f"1. {args.csv_template} íŒŒì¼ì„ ì—´ì–´ì„œ ì‹¤ì œ ë°ì´í„° ì‘ì„±")
    print(f"2. python create_eval_dataset.py --mode csv --input {args.csv_template} --output {args.output}")
    print(f"3. ìƒì„±ëœ {args.output}ì„ ì‹¤í—˜ì— ì‚¬ìš©")


if __name__ == "__main__":
    main()